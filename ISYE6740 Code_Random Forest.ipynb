{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4412197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Latex\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import random\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import random\n",
    "from numpy.linalg import inv\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy.sparse.linalg as ll\n",
    "import matplotlib as mpl\n",
    "import numpy.linalg as linalg\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dbe5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('stocksandindicators.pickle')\n",
    "df_AAPL= df['AAPL']\n",
    "historical_df = df_AAPL\n",
    "for i in range(1,8): # for 7 days\n",
    "    historical_df[\"Open_b_\"+str(i)] = df_AAPL['Open'].shift(i)\n",
    "    historical_df[\"High_b_\"+str(i)] = df_AAPL['High'].shift(i)\n",
    "    historical_df[\"Low_b_\"+str(i)]  = df_AAPL['Low'].shift(i)\n",
    "    historical_df[\"Close_b_\"+str(i)]= df_AAPL['Close'].shift(i)\n",
    "    historical_df['Volume_b_'+str(i)]      = df_AAPL['Volume'].shift(i)\n",
    "    historical_df[\"volume_fi_b_\"+str(i)] = df_AAPL['volume_fi'].shift(i)\n",
    "\n",
    "historical_df = historical_df.dropna() \n",
    "print(\"Historical Data Shape: \", historical_df.shape)\n",
    "historical_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad93286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('stocksandindicators.pickle')\n",
    "df_AAPL = pd.DataFrame()\n",
    "df_AAPL= df['AAPL']\n",
    "df_AAPL['Volume'].fillna(value=0, inplace=True)\n",
    "df_AAPL['volume_fi'].fillna(value=0, inplace=True)\n",
    "\n",
    "df_AAPL['Open'].fillna(method='ffill', inplace=True)\n",
    "df_AAPL['High'].fillna(method='ffill', inplace=True)\n",
    "df_AAPL['Low'].fillna(method='ffill', inplace=True)\n",
    "df_AAPL['Close'].fillna(method='ffill', inplace=True)\n",
    "df_AAPL['Close_lag'] = df_AAPL['Close'].shift(0)\n",
    "df_AAPL.tail(3)\n",
    "df_AAPL.set_index('Dates', inplace=True)\n",
    "X = df_AAPL.loc[:, (df_AAPL.columns != 'Close') & (df_AAPL.columns != 'Close_lag')]\n",
    "y = df_AAPL['Close_lag']\n",
    "features = np.array(X.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.05, random_state=642,shuffle=False)\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 5)\n",
    "rf.fit(X_train, np.ravel(y_train));\n",
    "predictions = rf.predict(X_test)\n",
    "df_Result = pd.DataFrame(y_test)\n",
    "df_Result['Predicted'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,15), facecolor='w', edgecolor='k')\n",
    "ax = plt.gca()  \n",
    "plt.plot(df_Result['Close_lag'], color = 'red', label = 'Real Closing Price')\n",
    "plt.plot(df_Result['Predicted'], color = 'blue', label = 'Predicted Closing Price')\n",
    "plt.title('Price Prediction', fontsize=40)\n",
    "df_test = df_Result.reset_index()\n",
    "x = df_test.index\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(18)\n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label1.set_fontsize(18)\n",
    "plt.xlabel('Time', fontsize=40)\n",
    "plt.ylabel('Price(USD) [Closed]', fontsize=40)\n",
    "plt.legend(loc=2, prop={'size': 25})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffe3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feat_labels = X.columns\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [feat_labels[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_mod(X,y,lenf, dates):\n",
    "    train_size = int(len(X)*0.95)\n",
    "    test_size= len(X)- train_size\n",
    "    x_train, x_test = X[0:train_size], X[train_size:len(X)]\n",
    "    y_train, y_test = y[0:train_size], y[train_size:len(y)]\n",
    "    datestrain, datestest = dates[0:train_size], dates[train_size:len(dates)]\n",
    "\n",
    "    scalerX = StandardScaler().fit(x_train)\n",
    "    scalerY = StandardScaler().fit(y_train)\n",
    "    \n",
    "    x_train = scalerX.transform(x_train)\n",
    "    y_train = scalerY.transform(y_train)\n",
    "    x_test = scalerX.transform(x_test)\n",
    "    y_test = scalerY.transform(y_test)\n",
    "      \n",
    "    #x_train = x_train.reshape((x_train.shape[0],lenf,1))\n",
    "    #x_test = x_test.reshape((x_test.shape[0],lenf,1))\n",
    "    #earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",  \n",
    "                                        #mode =\"min\", patience = 5,  \n",
    "                                        #restore_best_weights = True) \n",
    "    \n",
    "    \n",
    "    #x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.05, random_state=642,shuffle=False)\n",
    "    model = RandomForestRegressor(n_estimators = 1000, random_state = 5)\n",
    "    \n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    trainPredict = model.predict(x_train)\n",
    "    testPredict = model.predict(x_test)\n",
    "\n",
    "    # invert predictions\n",
    "    trainPredict_y = scalerY.inverse_transform(trainPredict)\n",
    "    testPredict_y = scalerY.inverse_transform(testPredict)\n",
    "    y_true_train = y[0:train_size]\n",
    "    y_true_test = y[-test_size:]\n",
    "\n",
    "    df_ytrue_train = pd.DataFrame({'Dates' : datestrain.values,'Close': y_true_train.ravel(), 'Close Predicted' : trainPredict_y.flatten()})\n",
    "    df_ytrue_test = pd.DataFrame({'Dates' : datestest.values, 'Close': y_true_test.ravel(), 'Close Predicted' : testPredict_y.flatten()})\n",
    "    #print('Model accuracy (%)')\n",
    "    Y_t=scalerY.inverse_transform(y_train)\n",
    "    y_test_T = scalerY.inverse_transform(y_test)\n",
    "    Accuracy = ((1-(metrics.mean_absolute_error(Y_t, trainPredict_y)/Y_t.mean()))*100)\n",
    "    #print('')\n",
    "    #print('Prediction performance')\n",
    "    MAE =((metrics.mean_absolute_error(y_test_T, testPredict)/y_test_T.mean())*100)\n",
    "    MSE=metrics.mean_squared_error(y_test_T,  testPredict)\n",
    "    RMSE=np.sqrt(MSE)\n",
    "    R2= metrics.r2_score(y_test_T,  testPredict)\n",
    "    return df_ytrue_train, df_ytrue_test, Accuracy, MAE, MSE, RMSE, R2, datestrain, datestest\n",
    "def preprocess(df):\n",
    "    df.drop(columns=['Split Coef'], inplace=True)\n",
    "    df.set_index('Dates', inplace=True)\n",
    "    X = df.loc[:, collist]\n",
    "    y = df[['Close']].values\n",
    "    features = np.array(X.columns)\n",
    "    return X, y, features    \n",
    "def maketrainplots(df_ytrue_train, indic_type, key,df_type):\n",
    "    fig, ax = plt.subplots(figsize= (9,5))\n",
    "    plt.plot(df_ytrue_train['Dates'], df_ytrue_train['Close'],\n",
    "                                label='Closing Price')\n",
    "    plt.plot(df_ytrue_train['Dates'], df_ytrue_train['Close Predicted'],'r--',\n",
    "                                label='Predicted Closing Price')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'data_project/Price Plots/{indic_type}/train_{indic_type}_{df_type}_{key}.png')\n",
    "    plt.close()\n",
    "def maketestplots(df_ytrue_test, indic_type, key, df_type):\n",
    "    fig, ax = plt.subplots(figsize= (9,5))\n",
    "    plt.plot(df_ytrue_test['Dates'], df_ytrue_test['Close'],\n",
    "                                label='Closing Price')\n",
    "    plt.plot(df_ytrue_test['Dates'], df_ytrue_test['Close Predicted'],'r--',\n",
    "                                label='Predicted Closing Price')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'data_project/Price Plots/{indic_type}/test_{indic_type}_{df_type}_{key}.png')\n",
    "    plt.close()\n",
    "if __name__ == \"__main__\":   \n",
    "    obj = pd.read_pickle(r'data_project/stocksandindicators.pickle')\n",
    "    sp500_df = pd.read_csv('data_project/Stocks in the SP 500 Index.csv')\n",
    "    indic_type = 'Trend'\n",
    "    df_indicators = pd.read_csv('data_project/LassoCoefficientsAllModels_partial_trend.csv')\n",
    "    df_indicators.rename(columns={'Unnamed: 0' : 'Stock'}, inplace=True)\n",
    "    df_indicators.set_index('Stock', inplace=True)\n",
    "    #sp500_df['Dividend yield'] = sp500_df['Dividend yield'].map(lambda x: x.rstrip('%'))\n",
    "    #sp500_df['Dividend yield'] = sp500_df['Dividend yield'].apply(pd.to_numeric)\n",
    "    #df_dividend = sp500_df.loc[sp500_df['Dividend yield']>0]\n",
    "    #df_not_dividend = sp500_df.loc[sp500_df['Dividend yield']==0]\n",
    "    \n",
    "    df_sector_IT = sp500_df.loc[sp500_df['GICS Sector']=='Information Technology']\n",
    "    df_sector_CS = sp500_df.loc[sp500_df['GICS Sector']=='Communication Services']\n",
    "    df_sector_CD = sp500_df.loc[sp500_df['GICS Sector']=='Consumer Discretionary']\n",
    "    df_sector_Fin = sp500_df.loc[sp500_df['GICS Sector']=='Financials']\n",
    "    df_sector_HC = sp500_df.loc[sp500_df['GICS Sector']=='Health Care']\n",
    "    df_sector_Energy = sp500_df.loc[sp500_df['GICS Sector']=='Energy']\n",
    "    df_sector_Staples = sp500_df.loc[sp500_df['GICS Sector']=='Consumer Staples']\n",
    "    df_sector_Utils = sp500_df.loc[sp500_df['GICS Sector']=='Utilities']\n",
    "    df_sector_Materials = sp500_df.loc[sp500_df['GICS Sector']=='Materials']\n",
    "    df_sector_Industrials = sp500_df.loc[sp500_df['GICS Sector']=='Industrials']\n",
    "    df_sector_RE = sp500_df.loc[sp500_df['GICS Sector']=='Real Estate']\n",
    "    \n",
    "    #df_dividend = df_dividend['Symbol'].tolist()\n",
    "    #df_not_dividend = df_not_dividend['Symbol'].tolist()\n",
    "    \n",
    "    df_sector_IT = df_sector_IT['Symbol'].tolist()\n",
    "    df_sector_CS = df_sector_CS['Symbol'].tolist()\n",
    "    df_sector_CD = df_sector_CD['Symbol'].tolist()\n",
    "    df_sector_Fin = df_sector_Fin['Symbol'].tolist()\n",
    "    df_sector_HC = df_sector_HC['Symbol'].tolist()\n",
    "    df_sector_Energy = df_sector_Energy['Symbol'].tolist()\n",
    "    df_sector_Staples = df_sector_Staples['Symbol'].tolist()\n",
    "    df_sector_Utils = df_sector_Utils['Symbol'].tolist()\n",
    "    df_sector_Materials = df_sector_Materials['Symbol'].tolist()\n",
    "    df_sector_Industrials = df_sector_Industrials['Symbol'].tolist()\n",
    "    df_sector_RE = df_sector_RE['Symbol'].tolist()\n",
    "    \n",
    "    #fulllist = [df_dividend,df_not_dividend,df_sector_IT,df_sector_CS,df_sector_CD,df_sector_Fin,df_sector_HC,\n",
    "    #            df_sector_Energy,df_sector_Staples,df_sector_Utils,df_sector_Materials,df_sector_Industrials,df_sector_RE]\n",
    "   # fulllist = [df_sector_Staples,df_sector_Utils,df_sector_Materials,df_sector_Industrials,df_sector_RE]#\n",
    "    fulllist = [df_sector_Energy,df_sector_IT,df_sector_CS,df_sector_CD,df_sector_Fin,df_sector_HC,\n",
    "                df_sector_Staples,df_sector_Utils,df_sector_Materials,df_sector_Industrials,df_sector_RE]\n",
    "    #splitnames = ['dividend', 'no dividend','Information Technology','Communication Services','Consumer Discretionary','Financials','Health Care',\n",
    "    #              'Energy','Consumer Staples','Utilities','Materials','Industrials','Real Estate']\n",
    "    #splitnames = ['Consumer Staples','Utilities','Materials','Industrials','Real Estate']#\n",
    "    splitnames = ['Energy','Information Technology','Communication Services','Consumer Discretionary','Financials','Health Care',\n",
    "                 'Consumer Staples','Utilities','Materials','Industrials','Real Estate']\n",
    "    ct = 0\n",
    "    \n",
    "    for dfl in fulllist:\n",
    "        df_temp = df_indicators[df_indicators.index.isin(dfl)]\n",
    "        lendft = len(df_temp)\n",
    "        params_list=[]\n",
    "        for col in df_temp:\n",
    "            count0 = df_temp[col].isin([0]).sum()\n",
    "            if (lendft - count0)/lendft < 0.7:\n",
    "                df_temp.drop(col, axis=1, inplace=True)\n",
    "            else:\n",
    "                params_list.append(f'{col}: {count0}')\n",
    "        \n",
    "        collist = df_temp.columns\n",
    "        df_errors = pd.DataFrame()\n",
    "        df_type = splitnames[ct]\n",
    "        with open(f'data_project/Price Plots/{indic_type}/parameters_{indic_type}_{df_type}.txt', 'w') as fp:\n",
    "            for item in params_list:\n",
    "                # write each item on a new line\n",
    "                fp.write(\"%s\\n\" % item)\n",
    "        for key in obj:\n",
    "            \n",
    "            if key in df_temp.index:\n",
    "                #idx_list.append(key)\n",
    "                X, y, features = preprocess(obj[key])\n",
    "                df_ytrue_train, df_ytrue_test, Accuracy, MAE, MSE, RMSE, R2, datestrain, datestest = RF_mod(X,y,len(features), obj[key].index)\n",
    "                maketrainplots(df_ytrue_train, indic_type, key, df_type)\n",
    "                maketestplots(df_ytrue_test, indic_type, key, df_type)\n",
    "                #print(key, X, features)\n",
    "                df_temp_errors = pd.DataFrame(columns=['Accuracy','MAE','MSE','RMSE','R2', 'Start Date Train', 'Start Date Test', 'End Date Test'])\n",
    "                df_temp_errors.loc[0] = [Accuracy, MAE, MSE,RMSE,R2, datestrain[0], datestest[0], datestest[-1]]\n",
    "                df_errors =pd.concat([df_errors,df_temp_errors])\n",
    "        df_errors.index=dfl\n",
    "        df_errors.to_csv(f'data_project/Price Plots/{indic_type}/errors_{indic_type}_{df_type}.csv')\n",
    "        print(splitnames[ct])\n",
    "        ct+=1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
